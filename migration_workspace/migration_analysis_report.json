{
  "analysis_summary": {
    "total_models": 4,
    "complexity_breakdown": {
      "Low": 0,
      "Medium": 2,
      "High": 2,
      "Unknown": 0
    },
    "total_parameters": 1894769,
    "migration_priority": [
      "DeepPhase",
      "TransitionNet",
      "DeepMimic",
      "StyleVAE"
    ]
  },
  "models": [
    {
      "name": "DeepPhase",
      "path": "../RSMT-Realtime-Stylized-Motion-Transition/",
      "architecture": {
        "type": "Autoencoder",
        "encoder_layers": [
          132,
          256,
          128,
          32
        ],
        "decoder_layers": [
          32,
          16,
          2
        ],
        "activation": "LeakyReLU",
        "loss_function": "MSE"
      },
      "parameters": 72690,
      "input_shape": [
        132
      ],
      "output_shape": [
        2
      ],
      "dependencies": [
        "torch",
        "torch.nn"
      ],
      "complexity": "Medium",
      "migration_notes": [
        "Standard feedforward architecture - good for MAX conversion",
        "LeakyReLU activation supported in MAX",
        "MSE loss function available in MAX",
        "Consider batch processing for better performance"
      ],
      "recommended_approach": {
        "strategy": "ONNX conversion with validation",
        "timeline": "3-5 days",
        "risk": "Medium"
      }
    },
    {
      "name": "StyleVAE",
      "path": "../RSMT-Realtime-Stylized-Motion-Transition/",
      "architecture": {
        "type": "Variational Autoencoder",
        "encoder_layers": [
          256,
          128,
          64
        ],
        "latent_dim": 256,
        "decoder_layers": [
          256,
          128,
          256
        ],
        "activation": "LeakyReLU",
        "loss_function": "VAE Loss (Reconstruction + KL)"
      },
      "parameters": 123712,
      "input_shape": [
        60,
        256
      ],
      "output_shape": [
        256
      ],
      "dependencies": [
        "torch",
        "torch.nn",
        "torch.distributions"
      ],
      "complexity": "High",
      "migration_notes": [
        "VAE architecture requires careful handling of sampling",
        "KL divergence loss needs custom implementation in MAX",
        "Reparameterization trick may need special attention",
        "Consider splitting encoder/decoder for easier conversion"
      ],
      "recommended_approach": {
        "strategy": "Phased migration with custom components",
        "timeline": "1-2 weeks",
        "risk": "High"
      }
    },
    {
      "name": "TransitionNet",
      "path": "../RSMT-Realtime-Stylized-Motion-Transition/",
      "architecture": {
        "type": "Feedforward Network",
        "layers": [
          321,
          256,
          128,
          63
        ],
        "activation": "ReLU",
        "loss_function": "MSE"
      },
      "parameters": 123455,
      "input_shape": [
        321
      ],
      "output_shape": [
        63
      ],
      "dependencies": [
        "torch",
        "torch.nn"
      ],
      "complexity": "Medium",
      "migration_notes": [
        "Standard feedforward - excellent for MAX conversion",
        "Large input dimension requires efficient tensor operations",
        "Consider input preprocessing optimization",
        "Good candidate for kernel fusion in MAX"
      ],
      "recommended_approach": {
        "strategy": "ONNX conversion with validation",
        "timeline": "3-5 days",
        "risk": "Medium"
      }
    },
    {
      "name": "DeepMimic",
      "path": "../pytorch_DeepMimic/",
      "architecture": {
        "type": "Reinforcement Learning (PPO)",
        "actor_layers": [
          1024,
          512
        ],
        "critic_layers": [
          1024,
          512
        ],
        "activation": "ReLU",
        "algorithm": "Proximal Policy Optimization"
      },
      "parameters": 1574912,
      "input_shape": null,
      "output_shape": null,
      "dependencies": [
        "torch",
        "torch.nn",
        "pybullet"
      ],
      "complexity": "High",
      "migration_notes": [
        "RL models require careful migration of training loop",
        "Actor-Critic architecture can be split into separate models",
        "Policy sampling needs special attention in MAX",
        "Consider migrating inference first, training later"
      ],
      "recommended_approach": {
        "strategy": "Phased migration with custom components",
        "timeline": "1-2 weeks",
        "risk": "High"
      }
    }
  ]
}